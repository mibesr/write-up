\section{Introduction}

\comment{ (1 pages) The thought flow: \begin{itemize} \item Faceted search gets
popular lately.  \item One possible way to improve faceted search is through
facet ranking, an issue that ordinary interface failed to address.  \item We
want the model assign high score to the facets discovered in high-relevance
documents.  \item An intuitive solution is to assign weighted score to facets,
but the complexity varies from model to model.  \item Our idea is to extend the
standard language modeling to offer ranking over the facets.  It is intuitively
appealing since we do not need another ``weighting scheme'' for facets.  \item
The task has no standard benchmark.  We created one in our own application.
\item Highlight contributions.  \item Present the outline. \end{itemize} }

Over the past few years, faceted search has started playing an essential role
in exploratory task for digital library applications.  While being recognized
as an eminent information seeking tool, usability of faceted search remains an
open issue for researchers to work on.  Conventional faceted search presents
the discovered facets based on the number of counts.  This type of arrangement
fails to take relevance into consideration. 

Conventional faceted search can be seen as an two-phase extension of the
ordinary retrieval task.  In the first phase, the retrieval engine collects a
set of documents that are relevant to the query $Q$, assigns each document a
\emph{relevance score}, and returns the set back to the frontend.  Different
system might implement this stage in slightly different way, but normally we
could expect that by the end of this stage, we will be able to obtain a set of
document-score pairs, i.e.,$D_Q = \{ d | d \in D \}$.  This set is called the
\emph{result set}.  Let us assume that the facet set assoicated with a document
$d$ is denoted as $F_d \subset F$.  Now, in the second phrase, the system scans
through the entire result set and put together a set of facets $F_Q$.  The
simplest and probably the most commonly-seen approach is through set union,
i.e., $F_Q = \cup_{d \in D_Q} F_d$.  

Another interesting aspect that we discovered in the development of testbed
systems is that users tend to follow top-ranked facets.  According to our
internal study on the click-through log, the average click-through rank of the
facets falls in the top 20\% of the presented facets.  This fact also motivates
our research toward integration of relevance into faceted interface, in which
users could gain better insight of the content even though they do not explicit
go through every facet that we discovered.

In this work, we attempt to improve faceted search usability by introducing the
notion of relevance into the facet interface.  

%--------------------------------------------------
% Employing a relational database backend is the easiest, while also the most
% practical, approach towards construction of this function.  The document
% contents are usually stored in one table and associated facet records in
% another, and then implement the search function with a plain SQL text match
% against the documents.  The set of facets associated with all the matched
% document and their corresponding counts of occurrences can be pulled out as
% easily with a join or SQL aggregation functions such as {\tt GROUP BY} and {\tt
% COUNT}.  The downside of this approach is we compromise retrieval quality in
% favor of ease of extra efforts because most of the modern relational database
% systems do not really support fuzzy-match in text fields, least to say the
% state-of-the-art document retrieval models.  A proposed workaround for this is
% to host retrieval engine and document representation somewhere else and access
% the RDBMS only for aggregating facet counts.  This could be done fairly easily
% by using the retrieved document identifiers to explicitly form a (probably very
% long) {\tt SELECT} query.  Unfortunately, this solution might not scale well,
% since serving data in an RDBMS way, on the other hand, can obstruct the
% interaction to the retrieval model and degrade the performance.
%-------------------------------------------------- 

\section{Model}

\comment{Here, instead of directly jumping into the model, we had better start with some rationales.}

Consider a document collection of size $N$, in which each document $d_j$ is
associated with a set of terms $T_j$ and a set of facets $F_j$.  We assume that
each term $t_i \in T_j$ and each facet $f_k \in F_j$ are drawn from are drawn
from two document-specific multinomials, one over the term domain and the other
over the facet domain, respectively.  We further assume that the former,
denoted as $\tau^{(j)}$, is drawn from a Dirichlet prior $\{ \alpha_i; i \in
[1, T] \}$ and the latter from another Dirichlet $\{ \beta_k; k \in [1, F] \}$.
The generative process can be described as follows: \footnote{A formal way to
model the generation of the corresponding set size $|T_j|$ and $|F_j|$ is
through Poisson processes.  For simplicity, in this work we assume these
numbers are pre-determined for each document $d_j$.} 

\begin{itemize} 
  \item For each document $d_j$, \begin{enumerate}
    \item Assign $d_j = j$
    \item $\tau^{(j)} \sim \textrm{Dirichlet}(\alpha_i; i \in [1, |T|])$
    \item $\phi^{(j)} \sim \textrm{Dirichlet}(\beta_k; i \in [1, |F|])$
    \item For $i \in \{ 1, \ldots, |T_j| \}$, $t_i \sim \textrm{Mult}(\tau^{(j)})$ 
    \item For $k \in \{ 1, \ldots, |F_j| \}$, $f_k \sim \textrm{Mult}(\phi^{(j)})$ 
  \end{enumerate}
\end{itemize}

Upon receiving a query $Q$, it is modeled as a new document $x$ in the
framework, in which the only observable variables are the query terms $q_i$'s;
the corresponding document node $x$ and facet $y$ remains unknown.  The entire
generative process in plate notation is shown in Figure~\ref{f:model}.
\footnote{Without loss of generality, the number of facets in the query is set
to 1. \comment{(Explain why.)}}  

\begin{figure}[ht!]
  \centering
  \psset{xunit=10mm,yunit=10mm}
  \begin{pspicture}(0,-2)(8,5)%\showgrid  % Uncomment to show grid!
    \SpecialCoor  % (a|b) means x-coord from 'a' and y-coord from 'b'.
    \psset{arrowscale=1.5}
    \rput(4.0,0.0){\GM@node[observed=true]{d}}\GM@label[angle=90]{d}{$d_j = j$}
    \rput(2.0,0.0){\GM@node[observed=true]{t}}\GM@label[angle=45]{t}{$t_i$}
    \rput(1.25, -0.75){\GM@plate{1.5}{1.5}{$|T_j|$}}
    \rput(6.0,0.0){\GM@node[observed=true]{f}}\GM@label[angle=45]{f}{$f_k$}
    \rput(5.25, -0.75){\GM@plate{1.5}{1.5}{$|F_j|$}}
    \rput(0.75, -1.25){\GM@plate{6.5}{2.5}{$N$}}

    \rput(4.0,4.0){\GM@node{x}}\GM@label[angle=45]{x}{$x$}
    \rput(2.0,4.0){\GM@node[observed=true]{q}}\GM@label[angle=45]{q}{$q_i$}
    \rput(1.25, 3.25){\GM@plate{1.5}{1.5}{$|Q|$}}
    \rput(6.0,4.0){\GM@node{y}}\GM@label[angle=45]{y}{$y$}

    \rput(2.0,2.0){\GM@node{tau}}\GM@label[angle=45]{tau}{$\tau$}
    \rput(6.0,2.0){\GM@node{phi}}\GM@label[angle=45]{phi}{$\phi$}
    \rput(0.0,0|tau){\GM@parameter{alpha}}\GM@label[angle=45]{alpha}{$\alpha$}
    \rput(8.0,0|phi){\GM@parameter{beta}}\GM@label[angle=45]{beta}{$\beta$}

    \ncline[arrows=->]{d}{t}
    \ncline[arrows=->]{d}{f}
    \ncline[arrows=->]{x}{q}
    \ncline[arrows=->]{x}{y}
    \ncline[arrows=->]{tau}{t}
    \ncline[arrows=->]{tau}{q}
    \ncline[arrows=->]{phi}{f}
    \ncline[arrows=->]{phi}{y}
    \ncline[arrows=->]{alpha}{tau}
    \ncline[arrows=->]{beta}{phi}
  \end{pspicture}

  \caption{A document-centric generative model.  The document $d_j$ generates a
  set of terms $T_j$ in which each term is represented as $t_i$; meanwhile, the
  document is associated with a set of facets $F_j$ in which each facet is
  denoted as $f_k$. \comment{FIXME: Introduce all the notations}. }
  \label{f:model}
\end{figure}

We are ready to recast faceted search as a baysian inference problem in this
framework.  Given a set of query $\mathbf{q}$, the task for retriving relevant
facets can be desribed as one of the following two optimization problems.  In
the first case, which we coin as the \emph{forward problem}, we search for the
most probable facet $f$ triggered by the query $\mathbf{q}$.

\begin{equation}y^*_{\rm f} = \arg\max_{y \in F} \Pr(y|\mathbf{q}, \mathbf{t},
\mathbf{d}, \mathbf{f}) \label{eq:forward} \end{equation}

In the second case, the search is done in \emph{backward} by looking for the
most probable facet $f$ that triggers the query $\mathbf{q}$.

\begin{equation}y^*_{\rm b} = \arg\max_{y \in F} \Pr(\mathbf{q}|y, \mathbf{t},
\mathbf{d}, \mathbf{f}) \label{eq:backward} \end{equation}

Here, we use the term \emph{trigger} to describe the relationship between the
facet and the term since there is no direct dependencies in between two nodes
in the graphical model.  By solving either the forward or the backward problem,
we may rank all the facets based on the likelihood scores.  Furthermore, in the
next section we show that both ranking schemes only differ in the
facet-specific normalization factor.

\section{Inference}
\comment{FIXME: All these derivation look too sketchy.}

\subsection{The Forward Problem}
We begin by deriving the solution for the forward problem shown in
Equation~\eqref{eq:forward}. 
\begin{eqnarray}
  \Pr(y|\mathbf{q}, \mathbf{t}, \mathbf{d}, \mathbf{f}) 
  &=& \sum_{x \in [1, N]} \Pr(y|x, \mathbf{q}, \mathbf{t}, \mathbf{d}, \mathbf{f}) \Pr(x|\mathbf{q}, \mathbf{t}, \mathbf{d}, \mathbf{f}) \nonumber\\
  &\propto& \sum_{x \in [1, N]} \left\{ \int \Pr(y|x, \phi^{(x)}) \Pr(\phi^{(x)}|d_x, \mathbf{f_x}) \mathrm{d}\phi^{(x)} \right. \nonumber\\
  && \left. \int \Pr(\mathbf{q}| x, \tau^{(x)}) \Pr(\tau^{(x)}|d_x, \mathbf{t_x})\mathrm{d}\tau^{(x)} \Pr(x) \right\} \nonumber\\
  &=& \sum_{x \in [1, N]} \frac{\beta + c_{k,x}}{|F|\beta + c_{\cdot,x}} \frac{\mathcal{B}(\{\alpha_i + c_{i,x} + c_{i,q} \})}{\mathcal{B}(\{\alpha_i + c_{i,x} \})} \Pr(x)
\end{eqnarray}
Note that $\mathcal{B}(\cdot)$ is the multinomial beta
function defined by \[\mathcal{B}(a_1, \ldots, a_n) = \frac{\prod_i
\Gamma(a_i)}{\Gamma(\sum_i a_i)}. \]
The last line follows the conjugacy of Dirichlet distribution, as in:
\begin{eqnarray*}
\Pr(\phi^{(x)}|d_x,\mathbf{f_x}) &\sim& \mathrm{Dirichlet}(\{\beta_k + c_{k,x}; \forall k \}) \\
\Pr(\tau^{(x)}|d_x, \mathbf{t_x}) &\sim& \mathrm{Dirichlet}(\{\alpha_i + c_{i,x}; \forall i \}).
\end{eqnarray*}

\subsection{The Backward Problem}
The backward problem shown in Equation~\eqref{eq:backward} is solved in similar way.
\begin{eqnarray}
  \Pr(\mathbf{q}|y, \mathbf{t}, \mathbf{d}, \mathbf{f}) 
  &=& \sum_{x \in [1, N]} \Pr(\mathbf{q}|x, y, \mathbf{t}, \mathbf{d}, \mathbf{f}) \Pr(x|y, \mathbf{t}, \mathbf{d}, \mathbf{f}) \nonumber\\
  &\propto& \sum_{x \in [1, N]} \left\{ \int \Pr(\mathbf{q}|x, \tau^{(x)}) \Pr(\tau^{(x)}|d_x, \mathbf{t_x}) \mathrm{d}\tau^{(x)} \right. \nonumber\\
  && \left. \int \Pr(y| x, \phi^{(x)}) \Pr(\phi^{(x)}|d_x, \mathbf{f_x})\mathrm{d}\phi^{(x)} \frac{\Pr(x)}{\Pr(y|\mathbf{t}, \mathbf{d}, \mathbf{f})} \right\} \nonumber\\
  &=& \frac{1}{\Pr(y|\mathbf{t}, \mathbf{d}, \mathbf{f})} \sum_{x \in [1, N]} \frac{\mathcal{B}(\{\alpha_i + c_{i,x} + c_{i,q} \})}{\mathcal{B}(\{\alpha_i + c_{i,x} \})} \frac{\beta + c_{k,x}}{|F|\beta + c_{\cdot,x}} \Pr(x) \nonumber
\end{eqnarray}

It is not difficult to see that the normalizing factor is in fact a similar summation.
$\Pr(y|\mathbf{t}, \mathbf{d}, \mathbf{f})$.
\begin{eqnarray}
  \Pr(y|\mathbf{t}, \mathbf{d}, \mathbf{f})
  &=& \sum_{x \in [1, N]} \Pr(y|x, \mathbf{t}, \mathbf{d}, \mathbf{f}) \Pr(x) \nonumber\\
  &=& \sum_{x \in [1, N]} \int \Pr(y|x, \phi^{(x)}) \Pr(\phi^{(x)}|d_x, \mathbf{f_x}) \mathrm{d}\phi^{(x)} \Pr(x) \nonumber\\
  &=& \sum_{x \in [1, N]} \frac{\beta + c_{k,x}}{|F|\beta + c_{\cdot,x}} \Pr(x) \nonumber\\
\end{eqnarray}

Therefore, the final form of Equation~\eqref{eq:backward} is as follow:
\begin{equation}
  \Pr(\mathbf{q}|y, \mathbf{t}, \mathbf{d}, \mathbf{f}) = 
  \frac{\sum_{x \in [1, N]} \frac{\mathcal{B}(\{\alpha_i + c_{i,x} + c_{i,q} \})}{\mathcal{B}(\{\alpha_i + c_{i,x} \})} \frac{\beta + c_{k,x}}{|F|\beta + c_{\cdot,x}} \Pr(x)}
  {\sum_{x \in [1, N]} \frac{\beta + c_{k,x}}{|F|\beta + c_{\cdot,x}} \Pr(x)}
\end{equation}

%--------------------------------------------------
% \begin{eqnarray}
%   \Pr(f|Q) &=& \sum_{d \in D} \Pr(f|d,Q) \Pr(d|Q) \nonumber\\
%   &=& \sum_{d \in D} \Pr(f|d) \Pr(d|Q) \nonumber\\
%   &\propto& \sum_{d \in D} \Pr(f|d) \Pr(Q|d) \label{eq:pr(f|Q)}\\
%   && \nonumber\\
%   \Pr(Q|d) &=& \prod_{q \in Q} \Pr(q|d) \nonumber\\
%   &\propto& \sum_{q \in Q} \log \Pr(q|d) \label{eq:pr(Q|d)}
% \end{eqnarray}
% 
% \paragraph{Estimation for $\Pr(Q|d)$.}
% 
% \begin{eqnarray}
%   \Pr(Q|d) &=& \exp \left(\sum_{q \in Q} \log \Pr(q|d) \right) \nonumber\\
%   &=& \exp \left(\sum_{q \in Q} \log \left[ \frac{f_{q,d} + \mu f_q / |C|}{|d| + \mu} \right] \right) \nonumber\\
%   &=& \exp \left(\sum_{q \in Q} \log \left( f_{q,d} + \mu f_q / |C| \right) - |Q| \log \left( |d| + \mu \right) \right) \nonumber\\
%   &=& K \times \exp \left( \sum_{q \in Q \cap d} \log \left( \frac{f_{q,d} |C|}{\mu f_q} + 1 \right) 
%   - |Q| \log \left( |d| + \mu \right) \right) 
% \end{eqnarray}
% where \[ K = \exp \left( |Q| \log \mu - |Q| \log |C| + \sum_{q \in Q} \log f_q \right). \]
% 
% \paragraph{Estimation for $\Pr(f|Q)$.}
% 
% \begin{eqnarray}
%   \Pr(f|Q) &\propto& \sum_{d \in D} \Pr(f|d) \Pr(Q|d) \nonumber\\
%   &=& \sum_{d \in \{d'|f \in d\}} \frac{c_{f,d}}{\mu_2 + c_d} \Pr(Q|d) + \sum_{d \in D} \frac{\mu_2 c_f / |F|}{\mu_2 + c_d} \Pr(Q|d)
% \end{eqnarray}
% 
% Let $c_{f,d} = 1$ and $K_f = \mu_2 c_f/|F|$.
% 
% \begin{eqnarray}
%   \Pr(f|q) &\propto& \sum_{d \in \{d'|f \in d\}} \frac{1}{\mu_2 + c_d} \Pr(Q|d) \\
%   && \quad + K_f \sum_{d \in D} \frac{1}{\mu_2 + c_d} \Pr(Q|d)
% \end{eqnarray}
%-------------------------------------------------- 

\section{Evaluation}

\comment{(1 page) The thought flow: \begin{itemize} \item The task is to rank
facets and measure model performance by precision/recall or NDCG.  \item No
standard benchmark.  We created a benchmark based on our own application.
\item Some checklist for making a benchmark: \begin{itemize} \item Documents
contains fulltext as well as facets. \item Query topics come from real queries,
i.e., query logs. \item Relevant judgment (from the in-house domain
expert) is available. \item Better start off with facets in only one aspect,
e.g., person names. \end{itemize}  \item Describe the dataset.  \item Describe
the preprocessing step for getting query topics.  \item Describe how we get
relevance judgments.  \item Describe the test runs (forward/backward model +
choice of priors).\end{itemize}}

One major difficulty that we faced in this work is the lack of standard
benchmark on the facet ranking task.  In this work, we decided to develop a
custom benchmark based on one text collection in our own applications.  The
advantage of using this benchmark lies in the availability of the following
three type of data:
\begin{itemize}
\item \emph{Facets}: Each document in the test collection is formed by the fulltext content and a list of relevant facets, which is exactly what we need as input of the facet ranking algorithm.
\item \emph{Query logs}: The test collection has been open to public access and accumulated certain amount of query logs; we figured it a good source for collecting query topics.
\item \emph{Relevance judgments}: The collection was studied by a group of in-house domain experts; we figured it easier for the domain experts to create relevant judgments on a dataset they are more familiar with.
\end{itemize}

The test corpus that we chose is the Tan-Hsin Archive \zhtw{(淡新檔案)}.  The
Tan-Hsin Archive is currently the most sizable and complete collection of
historical documents in Taiwan dating back from 1776 to 1895, when Taiwan was
ruled by Qing dynasty.  The collection contains nearly 20,000 administrative
and judicial documents, each comes as an XML file that contains
fulltext transcripts, metadata items, and associated human-annotated facets.
The average number of facets associated with a document in the dataset is
\comment{N.NNN}.  There are two types of facets involved in this study:
contents of certain selected fields, and hand-labeled concepts.  Hand-labeled
concepts, in fact, are created by a group of annotators.  All these information
are already made available in the metadata of the documents.

We took a subset of 15,314 documents from the collection as the test data.
To prepare the query topics, we consulted the database where the Tan-Hsin
Archive was previously made available and obtained a set of query log entries.
We preprocessed the log and removed all the entries were follow-up clicks on
the relevant facets and leave only original user queries in the file.  The
total amount of unique identifiable query topics is \comment{NN,NNN}.  After
manually removing incomplete and corrupted log entries, we let a domain expert
eyeball through the entire query set to filter out irrelevant queries.   The
final number on the query set size is \comment{NNN}.  Finally, \comment{NN}
topics were randomly drawn from the population and used in the evaluation.

\section{Results}

\comment{ (2 pages) Here we present the experimental results.  Precision/recall
or NDCG plot would be great.  Another way to evaluate is the Spearman's rho by asking
the domain experts to rank the facets explicitly and the annotations should
serve as gold standard for all the models to compare with. }

\section{Related Work}

\comment{ (Half a page) Introduce the related work in the following domains:
(1) language modeling, (2) faceted search, and (3) expert finding. }

%--------------------------------------------------
% Along with the wide acceptance of faceted search interface in the digital
% library community, an noticable amount of efforts has recently been put on
% usability tests and discovery of more advanced usage.  Previous efforts
% include... \comment{ Related work }
%-------------------------------------------------- 

Among the previous research, one closest effort to our approach is found in the
domain of expert finding.  Balog et al. \cite{balog2009language} proposed a
language modeling framework with the similar rationale to extend the use of
language model to the underlying co-occurrence statistics by exploiting
person-term and person-document links.  The difference between our contribution
and theirs lies, not only in the application domain, but in the way relevance
is introduced into the model against the facets and the explicit scoring
formula for online query support.
 
\section{Discussion and Concluding Remarks}

\comment{ (1 pages) Several issues that should be brought up here: (1) Why
relevance is also important in exploratory task, (2) the possible opposite
formulation of the model for novelty discovery (i.e., $\Pr(Q|f)$), and (3)
possible future directions.  Also draw conclusion here. }

\section{Acknowledgments}

We thank Po-Yu Chen for his support on preparation of the test data.  The
research efforts described in this paper are supported under the National Taiwan
University Digital Archives Project (Project No.  NSC-98-2631-H-002-005), which
is sponsored by National Science Council, Taiwan, 
