\section{Introduction}

\comment{ (2 pages) The thought flows: \begin{itemize} \item Faceted search is
getting popular in applications.  \item Ordinary setup failed to address
relevnce in the presentation of discovered facets.  \item Our idea to employ an
simple extension of the standard language modeling and applying it to the
scenario.  \item A little bit about previous/similar efforts.  \item Highlight
contributions.  \item Introduce the outline. \end{itemize} }

%--------------------------------------------------
% In the past few years, the faceted search interface has been introduced in
% various digital library applications and has also been shown generally useful
% to the users in exploratory and information seeking tasks.  
%-------------------------------------------------- 

%--------------------------------------------------
% Query-dependent faceted navigation did not received as much attention until
% recently, when faceted search interface started being recognized as an eminent
% information seeking tool in various kinds of digital library applications.  In
% the technical respect, the major obstacle for employing this technique in a
% real-world setup lies in the time complexity.  When facing a user query, the
% retrieval system that supports such a function would first put together a
% complete list of document identifiers that covers all the documents that match
% the query from the inverted index, explicitly scan through the forward index
% that maps a document to a set of associated facets for all the matched
% document, collect facet captions and counts, and finally return all these
% information back to the user.  Since the operation involves a set of results
% that is only known in run-time, its complexity is largely $O(K \times |R|)$ in
% time, where $K$ denotes an average number of facets being associated with a
% document, and $|R|$ denotes the size of the query result set.  
% 
% Employing a relational database backend is the easiest, while also the most
% practical, approach towards construction of this function.  The document
% contents are usually stored in one table and associated facet records in
% another, and then implement the search function with a plain SQL text match
% against the documents.  The set of facets associated with all the matched
% document and their corresponding counts of occurrences can be pulled out as
% easily with a join or SQL aggregation functions such as {\tt GROUP BY} and {\tt
% COUNT}.  The downside of this approach is we compromise retrieval quality in
% favor of ease of extra efforts because most of the modern relational database
% systems do not really support fuzzy-match in text fields, least to say the
% state-of-the-art document retrieval models.  A proposed workaround for this is
% to host retrieval engine and document representation somewhere else and access
% the RDBMS only for aggregating facet counts.  This could be done fairly easily
% by using the retrieved document identifiers to explicitly form a (probably very
% long) {\tt SELECT} query.  Unfortunately, this solution might not scale well,
% since serving data in an RDBMS way, on the other hand, can obstruct the
% interaction to the retrieval model and degrade the performance.
%-------------------------------------------------- 

%--------------------------------------------------
% In the simplest case, retrieval of query-dependent facets can be done in two
% phases: One for retriving the list of documents that match the given query, and
% the other for collecting all the associated facets for each retrieved document.
% With careful design of the backend data structure, the first phase normally
% returns in a very short time; the running time of the second phase, on the
% other hand, would usually grow as a multiple of the first one.  Ironically, it
% turns out generation of all the associated facets does require a linear scan
% through the entire result set, while the retrieval function does only a small
% amount of that size----since most search interfaces return only a fixed amount
% of document at a time when facing a new query (i.e., say top-$k$ in the first page), 
% and most of the user session would not last longer than than a few pages of results.
%-------------------------------------------------- 

%--------------------------------------------------
% \comment{ Argue that it takes enormous computational resources to produce the exact count
% for the facets, even with a RDBMS-based implementation. }
% 
% We discovered that the generation of query-dependent facets takes more than
% 50\% of the entire process time on one of our testbed system backed by language
% model.  A further look reveals that most of the CPU time are spent scanning the
% forward index. \comment{ Observation 1: Takes time to process document-by-document }
% 
% An interesting aspect that we discovered in the development of digital library
% systems is that users tend to follow top-ranked facets.  According to our
% records, the average click-through rank of the facets falls in the top 20\% of
% the presented facets. \comment{ Observation 2: Users tend to process only a small
% amount of given information, especially those pieces presented as more relevant
% than others.  They might not really look at the numbers.  The key is the rank.
% }
% 
% This work is motivated by the aforementioned observation... \comment{ \it Motivations:
% speed-up and support for state-of-the-art retrieval functions.  }
% 
% Our contribution lies in ... \comment{ Contributions }
% 
% Along with the wide acceptance of faceted search interface in the digital
% library community, an noticable amount of efforts has recently been put on
% usability tests and discovery of more advanced usage.  Previous efforts
% include... \comment{ Related work }
%-------------------------------------------------- 

\section{Model}

\comment{(3 pages) This section should cover the following three technical aspects of the
model: (1) mathematical framework stemmed from the basic language modeling
approach, (2) the required modification to the index structure, and (3)
complexity analysis.}

%--------------------------------------------------
% \section{Approximate Query-Dependent Faceted Navigation}
% 
% \subsection{Index Structure} 
% The guideline in development of approximate facet count retrieval algorithm is
% to prevent access to the document forward index.  \comment{ The key for speed-up
% is to not scanning through the index }
% 
% One way to do it is to build up a term-facet inverted index.  We prefetch all
% the associated facets and corresponding counts in the relevant set and store
% all these information in the inverted structure.  The example.... \comment{ The
% idea of building the inverted index }
% 
% Practical concerns for such arrangement incluce ... \comment{ Here we address
% the trick that we use to speed up the computation.  We might also want to
% address other possibilities for achieving the same goal. }
% 
% \subsection{Aggregation Methods}
% 
% An straightforward idea for aggregating the results for all the query terms is
% to average the facet counts. \comment{ Average }
% 
% By viewing the facet counts ... \comment{ Maximum }
% 
% \comment{ Interpolation }
% 
% \subsection{Error estimation} 
% We recast the problem as rank-correlation optimization problem.  \comment{ Here we
% elaborate on developing faceted navigation in conventional approach, and we
% formulate the approximated version of the problem. }
% 
% \comment{ Here we address how likely we are about to
% introduce errors, and how large it could be. }
%-------------------------------------------------- 

\section{Evaluation}

\comment{(1 1/2 pages) We briefly introduce the way we evaluate the performance.  Performance
could be measured in terms of precision/recall (or accuracy only) by letting a
domain expert explicitly annotating the entire query set.  Then we introduce
the benchmark (Dansin dataset and the corresponding query set).}

We use Dansin dataset as our reference corpus.  The dataset contains N,NNN
documents.  Each documents comes in as an XML file that contains fulltext
transcripts, metadata items, and associated human-selected facets.  The average
number of facets associated with a document in Dansin dataset is N.NNN.  There
are two types of facets involved in this study: contents of certain selected
fields, and hand-labeled concepts.  Hand-labeled concepts, in fact, are created
by a group of annotators.  All these information are already made available in
the metadata of the documents.

The major challenge for conducting such an evaluation task is to devise a set
of query topics.  Since most of the digital libraries are very much
domain-specific, it is difficult to find a standard reference query topics that
could be used across studies.  The approach that we took was to look for
session query logs in the relevant domain.  In the end, we took a copy of the
query log in 2009 from the DARC system which was developed and maintained by
Digital Archives Research Center.  

We preprocessed the log and remove all the entries were follow-up clicks on the
relevant facets and leave only original user queries in the file.  The total
amount of unique identifiable query topics is NN,NNN.  300 topics were randomly
drawn from the population and gone through human inspection.  Since the DARC
system is an aggregation service of a number of underlying database system, it
is possible that the query log contains irrelevant topics to the Dansin set.
Finally 151 topics were selected and used in the evaluation.

\comment{ Here we describe our effort for a number of proposed models.  The
following items shall be addressed in order: Experimental runs: baseline,
fuzzy-min, interpolation, and top-k.  }

\section{Results}

\comment{ (2 pages) Here we present the experimental results.  Precision/recall
plot would be great.  Another way to evaluate is the Spearman's rho by asking
the domain experts to rank the facets explicitly and the annotations should
serve as gold standard for all the models to compare with. }

\section{Discussion and Concluding Remarks}

\comment{ (2 pages) Several issues that should be brought up here: (1) Why relevance is also important in exploratory task, (2) the possible opposite formulation of the model for novelty discovery (i.e., $\Pr(Q|f)$), and (3) possible future directions.  Also draw conclusion here. }

%--------------------------------------------------
% \subsection{Measures}
% 
% The evaluation measures we used to assess the similarity between the original
% facets and the approximation is as follows.
% 
% \begin{enumerate}
% \item $p$-norm: The measure evaluates the distance between two vectors.  In this work, we use only L1 and L2 norms.
% \item Jaccard coefficient: The measure assesses the similarity between two sets, defined by
% \[ J(X,Y) = \frac{X \cap Y}{X \cup Y}. \]
% \item Spearman's rho: The measure assesses the rank correlation between two rank lists, defined by
% \[ \rho(X,Y) = 1. \]
% \end{enumerate}
% 
% \subsection{Results}
% Here we demonstrate the experimental results and give a brief analysis.
%-------------------------------------------------- 

\section{Acknowledgments}

\comment{ A few names shall be mentioned here, including NTU DTRAP and its corresponding funding project, and Po-Yu Chen. }

